{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d09203eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\ray\\thirdparty_files\n",
      "c:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\python311.zip\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\DLLs\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\n",
      "c:\\Users\\Alexey\\venvs\\recsys_project\n",
      "\n",
      "c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\n",
      "c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\win32\n",
      "c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\Pythonwin\n",
      "ProtoMF\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "protomf_path = Path(\"./ProtoMF/\")\n",
    "sys.path.append(protomf_path.__str__())\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from confs.hyper_params import (anchor_hyper_params,\n",
    "                                item_proto_chose_original_hyper_params,\n",
    "                                mf_hyper_params,\n",
    "                                proto_double_tie_chose_original_hyper_params,\n",
    "                                user_proto_chose_original_hyper_params)\n",
    "from experiment_helper import start_hyper, start_multiple_hyper\n",
    "\n",
    "from utilities.consts import SINGLE_SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b02a2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ray import tune\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from scipy import sparse as sp\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data.dataset import T_co\n",
    "\n",
    "from feature_extraction.feature_extractor_factories import \\\n",
    "    FeatureExtractorFactory\n",
    "from feature_extraction.feature_extractors import FeatureExtractor\n",
    "from rec_sys_folder.protomf_dataset import get_protorecdataset_dataloader\n",
    "from rec_sys_folder.rec_sys import RecSys\n",
    "from rec_sys_folder.tester import Tester\n",
    "from rec_sys_folder.trainer import Trainer\n",
    "from utilities.consts import (CPU_PER_TRIAL, DATA_PATH, GPU_PER_TRIAL,\n",
    "                              MAX_PATIENCE, NEG_VAL, NUM_SAMPLES, NUM_WORKERS,\n",
    "                              OPTIMIZING_METRIC, PROJECT_NAME, SEED_LIST,\n",
    "                              SINGLE_SEED, WANDB_API_KEY)\n",
    "from utilities.eval import Evaluator\n",
    "from utilities.utils import generate_id, reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c4d057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0ff974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba4b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(conf: argparse.Namespace, is_train: bool = True):\n",
    "    if is_train:\n",
    "        train_loader = get_protorecdataset_dataloader(\n",
    "            data_path=conf.data_path,\n",
    "            split_set=\"train\",\n",
    "            n_neg=conf.neg_train,\n",
    "            neg_strategy=conf.train_neg_strategy,\n",
    "            batch_size=conf.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            prefetch_factor=5,\n",
    "        )\n",
    "\n",
    "        val_loader = get_protorecdataset_dataloader(\n",
    "            data_path=conf.data_path,\n",
    "            split_set=\"val\",\n",
    "            n_neg=NEG_VAL,\n",
    "            neg_strategy=conf.eval_neg_strategy,\n",
    "            batch_size=conf.val_batch_size,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "        test_loader = get_protorecdataset_dataloader(\n",
    "            data_path=conf.data_path,\n",
    "            split_set=\"test\",\n",
    "            n_neg=NEG_VAL,\n",
    "            neg_strategy=conf.eval_neg_strategy,\n",
    "            batch_size=conf.val_batch_size,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"train_loader\": train_loader,\n",
    "            \"val_loader\": val_loader,\n",
    "            \"test_loader\": test_loader,\n",
    "        }\n",
    "    else:\n",
    "        test_loader = get_protorecdataset_dataloader(\n",
    "            data_path=conf.data_path,\n",
    "            split_set=\"test\",\n",
    "            n_neg=NEG_VAL,\n",
    "            neg_strategy=conf.eval_neg_strategy,\n",
    "            batch_size=conf.val_batch_size,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "        return {\"test_loader\": test_loader}\n",
    "\n",
    "\n",
    "def start_training(config):\n",
    "    config = argparse.Namespace(**config)\n",
    "    print(config)\n",
    "\n",
    "    data_loaders_dict = load_data(config)\n",
    "\n",
    "    reproducible(config.seed)\n",
    "\n",
    "    # trainer = Trainer(data_loaders_dict['train_loader'], data_loaders_dict['val_loader'], data_loaders_dict['test_loader'], config)\n",
    "    trainer = Trainer(\n",
    "        data_loaders_dict[\"train_loader\"], data_loaders_dict[\"val_loader\"], config\n",
    "    )\n",
    "\n",
    "    trainer.run()\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "def start_testing(config, model_load_path: str):\n",
    "    config = argparse.Namespace(**config)\n",
    "    print(config)\n",
    "\n",
    "    data_loaders_dict = load_data(config, is_train=False)\n",
    "\n",
    "    reproducible(config.seed)\n",
    "\n",
    "    tester = Tester(data_loaders_dict[\"test_loader\"], config, model_load_path)\n",
    "\n",
    "    metric_values = tester.test()\n",
    "    return metric_values\n",
    "\n",
    "\n",
    "def start_hyper(conf: dict, model: str, dataset: str, seed: int = SINGLE_SEED):\n",
    "    print(\"Starting Hyperparameter Optimization\")\n",
    "    print(f\"Seed is {seed}\")\n",
    "\n",
    "    # Search Algorithm\n",
    "    search_alg = HyperOptSearch(random_state_seed=seed)\n",
    "\n",
    "    if dataset == \"lfm2b-1mon\":\n",
    "        scheduler = ASHAScheduler(grace_period=4)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    # Logger\n",
    "    callback = WandbLoggerCallback(\n",
    "        project=PROJECT_NAME,\n",
    "        log_config=True,\n",
    "        api_key=WANDB_API_KEY,\n",
    "        reinit=True,\n",
    "        force=True,\n",
    "        job_type=\"train/val\",\n",
    "        tags=[model, str(seed), dataset],\n",
    "    )\n",
    "\n",
    "    # Hostname\n",
    "    host_name = platform.uname()\n",
    "\n",
    "    # Dataset\n",
    "    data_path = DATA_PATH\n",
    "    conf[\"data_path\"] = os.path.join(data_path, dataset)\n",
    "\n",
    "    # Seed\n",
    "    conf[\"seed\"] = seed\n",
    "\n",
    "    group_name = f\"{model}_{dataset}_{seed}\"\n",
    "    tune.register_trainable(group_name, start_training)\n",
    "    analysis = tune.run(\n",
    "        group_name,\n",
    "        config=conf,\n",
    "        name=generate_id(prefix=group_name),\n",
    "        resources_per_trial={\"gpu\": GPU_PER_TRIAL, \"cpu\": CPU_PER_TRIAL},\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search_alg,\n",
    "        num_samples=NUM_SAMPLES,\n",
    "        callbacks=[callback],\n",
    "        metric=\"_metric/\" + OPTIMIZING_METRIC,\n",
    "        mode=\"max\",\n",
    "    )\n",
    "    metric_name = \"_metric/\" + OPTIMIZING_METRIC\n",
    "    best_trial = analysis.get_best_trial(metric_name, \"max\", scope=\"all\")\n",
    "    best_trial_config = best_trial.config\n",
    "    best_trial_checkpoint = os.path.join(\n",
    "        analysis.get_best_checkpoint(best_trial, metric_name, \"max\"), \"best_model.pth\"\n",
    "    )\n",
    "\n",
    "    wandb.login(key=WANDB_API_KEY)\n",
    "    wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        group=\"test_results\",\n",
    "        config=best_trial_config,\n",
    "        name=group_name,\n",
    "        force=True,\n",
    "        job_type=\"test\",\n",
    "        tags=[model, str(seed), dataset],\n",
    "    )\n",
    "    metric_values = start_testing(best_trial_config, best_trial_checkpoint)\n",
    "    wandb.finish()\n",
    "    return metric_values\n",
    "\n",
    "\n",
    "def start_multiple_hyper(\n",
    "    conf: dict, model: str, dataset: str, seed_list: list = SEED_LIST\n",
    "):\n",
    "    print(\"Starting Multi-Hyperparameter Optimization\")\n",
    "    print(\"seed_list is \", seed_list)\n",
    "    metric_values_list = []\n",
    "    mean_values = dict()\n",
    "\n",
    "    for seed in seed_list:\n",
    "        metric_values_list.append(start_hyper(conf, model, dataset, seed))\n",
    "\n",
    "    for key in metric_values_list[0].keys():\n",
    "        _sum = 0\n",
    "        for metric_values in metric_values_list:\n",
    "            _sum += metric_values[key]\n",
    "        _mean = _sum / len(metric_values_list)\n",
    "\n",
    "        mean_values[key] = _mean\n",
    "\n",
    "    group_name = f\"{model}_{dataset}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ccf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_param = {\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"n_epochs\": 10,\n",
    "    \"eval_neg_strategy\": \"uniform\",\n",
    "    \"val_batch_size\": 256,\n",
    "    \"train_batch_size\": 256,\n",
    "    \"data_path\": protomf_path / \"data/ml\",\n",
    "    \"NUM_WORKERS\": 1,\n",
    "    \"rec_sys_param\": {\"use_bias\": 0},\n",
    "}\n",
    "\n",
    "base_hyper_params = {\n",
    "    **base_param,\n",
    "    \"neg_train\": 99,\n",
    "    \"neg_val\": 99,\n",
    "    \"train_neg_strategy\": \"uniform\",  # tune.choice(['popular', 'uniform']),\n",
    "    \"loss_func_name\": \"sampled_softmax\",  # tune.choice(['bce', 'bpr', 'sampled_softmax']),\n",
    "    \"batch_size\": np.random.randint(64, 512),\n",
    "    \"optim_param\": {\n",
    "        \"optim\": \"adagrad\",\n",
    "        \"wd\": np.random.uniform(low=1e-4, high=1e-2),\n",
    "        \"lr\": np.random.uniform(low=1e-4, high=1e-1),\n",
    "    },\n",
    "}\n",
    "user_proto_chose_original_hyper_params = {\n",
    "    **base_hyper_params,\n",
    "    \"loss_func_aggr\": \"mean\",\n",
    "    \"ft_ext_param\": {\n",
    "        \"ft_type\": \"prototypes\",\n",
    "        \"embedding_dim\": np.random.randint(10, 100),  # tune.randint(10, 100),\n",
    "        \"user_ft_ext_param\": {\n",
    "            \"ft_type\": \"prototypes\",\n",
    "            \"sim_proto_weight\": np.random.uniform(\n",
    "                low=1e-3, high=10\n",
    "            ),  # tune.loguniform(1e-3, 10),\n",
    "            \"sim_batch_weight\": np.random.uniform(low=1e-3, high=10),\n",
    "            \"use_weight_matrix\": False,\n",
    "            \"n_prototypes\": np.random.randint(10, 100),  # tune.randint(10, 100),\n",
    "            \"cosine_type\": \"shifted\",\n",
    "            \"reg_proto_type\": \"max\",\n",
    "            \"reg_batch_type\": \"max\",\n",
    "        },\n",
    "        \"item_ft_ext_param\": {\n",
    "            \"ft_type\": \"embedding\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "user_proto_chose_original_hyper_params = argparse.Namespace(\n",
    "    **user_proto_chose_original_hyper_params\n",
    ")\n",
    "\n",
    "proto_double_tie_chose_original_hyper_params = {\n",
    "    \"loss_func_aggr\": \"mean\",\n",
    "    \"ft_ext_param\": {\n",
    "        \"ft_type\": \"prototypes_double_tie\",\n",
    "        \"embedding_dim\": 100,  # tune.randint(10, 100),\n",
    "        \"item_ft_ext_param\": {\n",
    "            \"ft_type\": \"prototypes_double_tie\",\n",
    "            \"sim_proto_weight\": 1e-3,  # tune.loguniform(1e-3, 10),\n",
    "            \"sim_batch_weight\": 1e-3,  # tune.loguniform(1e-3, 10),\n",
    "            \"use_weight_matrix\": False,\n",
    "            \"n_prototypes\": 5,  # tune.randint(10, 100),\n",
    "            \"cosine_type\": \"shifted\",\n",
    "            \"reg_proto_type\": \"max\",\n",
    "            \"reg_batch_type\": \"max\",\n",
    "        },\n",
    "        \"user_ft_ext_param\": {\n",
    "            \"ft_type\": \"prototypes_double_tie\",\n",
    "            \"sim_proto_weight\": 1e-3,  # tune.loguniform(1e-3, 10),\n",
    "            \"sim_batch_weight\": 1e-3,  # tune.loguniform(1e-3, 10),\n",
    "            \"use_weight_matrix\": False,\n",
    "            \"n_prototypes\": 100,  # tune.randint(10, 100),\n",
    "            \"cosine_type\": \"shifted\",\n",
    "            \"reg_proto_type\": \"max\",\n",
    "            \"reg_batch_type\": \"max\",\n",
    "        },\n",
    "    },\n",
    "    \"checkpoint_dir\": \"experiments\",\n",
    "    **base_hyper_params,\n",
    "}\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# proto_double_tie_chose_original_hyper_params = argparse.Namespace(**proto_double_tie_chose_original_hyper_params)\n",
    "# proto_double_tie_chose_original_hyper_params = OmegaConf.create(proto_double_tie_chose_original_hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f1b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16066d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loaders_dict = load_data(proto_double_tie_chose_original_hyper_params)\n",
    "# config = proto_double_tie_chose_original_hyper_params\n",
    "# trainer = Trainer(data_loaders_dict['train_loader'], data_loaders_dict['val_loader'],  config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49add579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "794d0659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-24 20:41:18,397] A new study created in memory with name: no-name-2c38d3af-9356-4cbf-9b00-ea67cc1a00d9\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1459be54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\AppData\\Local\\Temp\\ipykernel_24884\\3566805594.py:7: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  prototypes1 = trial.suggest_int('prototypes1', 20, 100, 20)\n",
      "C:\\Users\\Alexey\\AppData\\Local\\Temp\\ipykernel_24884\\3566805594.py:8: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  prototypes2 = trial.suggest_int('prototypes2', 20, 100, 20)\n",
      "C:\\Users\\Alexey\\AppData\\Local\\Temp\\ipykernel_24884\\3566805594.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  embeddings_dim = trial.suggest_int(\"embedding_dim\", 50, 400, 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Built ProtoRecDataset module \n",
      "- data_path: ProtoMF\\data\\ml \n",
      "- n_users: 6028 \n",
      "- n_items: 3123 \n",
      "- n_interactions: 545656 \n",
      "- split_set: train \n",
      "- n_neg: 99 \n",
      "- neg_strategy: uniform \n",
      "\n",
      "Loading data\n",
      "Built ProtoRecDataset module \n",
      "- data_path: ProtoMF\\data\\ml \n",
      "- n_users: 6028 \n",
      "- n_items: 3123 \n",
      "- n_interactions: 14196 \n",
      "- split_set: val \n",
      "- n_neg: 99 \n",
      "- neg_strategy: uniform \n",
      "\n",
      "Loading data\n",
      "Built ProtoRecDataset module \n",
      "- data_path: ProtoMF\\data\\ml \n",
      "- n_users: 6028 \n",
      "- n_items: 3123 \n",
      "- n_interactions: 13952 \n",
      "- split_set: test \n",
      "- n_neg: 99 \n",
      "- neg_strategy: uniform \n",
      "\n",
      "--- Building FeatureExtractor model ---\n",
      "Built Embedding model \n",
      "- n_objects: 6028 \n",
      "- embedding_dim: 100 \n",
      "- max_norm: None\n",
      "- only_positive: False\n",
      "Built PrototypeEmbedding model \n",
      "- n_prototypes: 100 \n",
      "- use_weight_matrix: False \n",
      "- sim_proto_weight: 0.001 \n",
      "- sim_batch_weight: 0.001 \n",
      "- reg_proto_type: max \n",
      "- reg_batch_type: max \n",
      "- cosine_type: shifted \n",
      "\n",
      "--- Finished building FeatureExtractor model ---\n",
      "\n",
      "--- Building FeatureExtractor model ---\n",
      "Built Embedding model \n",
      "- n_objects: 6028 \n",
      "- embedding_dim: 100 \n",
      "- max_norm: None\n",
      "- only_positive: False\n",
      "Built Embeddingw model \n",
      "- out_dimension: 100 \n",
      "- use_bias: False \n",
      "\n",
      "--- Finished building FeatureExtractor model ---\n",
      "\n",
      "--- Building FeatureExtractor model ---\n",
      "Built Embedding model \n",
      "- n_objects: 3123 \n",
      "- embedding_dim: 100 \n",
      "- max_norm: None\n",
      "- only_positive: False\n",
      "Built PrototypeEmbedding model \n",
      "- n_prototypes: 100 \n",
      "- use_weight_matrix: False \n",
      "- sim_proto_weight: 0.001 \n",
      "- sim_batch_weight: 0.001 \n",
      "- reg_proto_type: max \n",
      "- reg_batch_type: max \n",
      "- cosine_type: shifted \n",
      "\n",
      "--- Finished building FeatureExtractor model ---\n",
      "\n",
      "--- Building FeatureExtractor model ---\n",
      "Built Embedding model \n",
      "- n_objects: 3123 \n",
      "- embedding_dim: 100 \n",
      "- max_norm: None\n",
      "- only_positive: False\n",
      "Built Embeddingw model \n",
      "- out_dimension: 100 \n",
      "- use_bias: False \n",
      "\n",
      "--- Finished building FeatureExtractor model ---\n",
      "\n",
      "Built ConcatenateFeatureExtractors model \n",
      "- model_1: PrototypeEmbedding \n",
      "- model_2: EmbeddingW \n",
      "- invert: False \n",
      "\n",
      "Built ConcatenateFeatureExtractors model \n",
      "- model_1: PrototypeEmbedding \n",
      "- model_2: EmbeddingW \n",
      "- invert: True \n",
      "\n",
      "Built RecSys module \n",
      "- n_users: 6028 \n",
      "- n_items: 3123 \n",
      "- user_feature_extractor: ConcatenateFeatureExtractors \n",
      "- item_feature_extractor: ConcatenateFeatureExtractors \n",
      "- loss_func_name: sampled_softmax \n",
      "- use_bias: False \n",
      "\n",
      "Built Optimizer  \n",
      "- name: adagrad \n",
      "- lr: 0.06032999298697848 \n",
      "- wd: 0.005134675829337597 \n",
      "\n",
      "Built Trainer module \n",
      "- n_epochs: 10 \n",
      "- loss_func_name: sampled_softmax \n",
      "- loss_func_aggr: mean \n",
      "- device: cuda \n",
      "- optimizing_metric: hit_ratio@10 \n",
      " - checkpoint_dir: experiments\\12242023.204136 \n",
      "\n",
      "Validation started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824b63080af3469e8ee0ce306decbd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\ray\\train\\_internal\\session.py:638: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init - Avg Val Value 0.103 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Epoch Avg Train Loss 3.772 \n",
      "\n",
      "Validation started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e0ab3038ca4ae6a7f5219abd1f79a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Avg Val Value 1.213 \n",
      "\n",
      "Epoch 0 - New best model found (val value 1.213) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-12-24 21:41:35,248] Trial 0 failed with parameters: {'prototypes1': 100, 'prototypes2': 100, 'embedding_dim': 300} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alexey\\AppData\\Local\\Temp\\ipykernel_24884\\3566805594.py\", line 22, in objective\n",
      "    return trainer.run(trial)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\\rec_sys_folder\\trainer.py\", line 113, in run\n",
      "    for u_idxs, i_idxs, labels in track(self.train_loader, total=len(self.train_loader)):\n",
      "  File \"c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\rich\\progress.py\", line 168, in track\n",
      "    yield from progress.track(\n",
      "  File \"c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\rich\\progress.py\", line 1209, in track\n",
      "    for value in sequence:\n",
      "  File \"c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1328, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1294, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1132, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 110, in rebuild_tensor\n",
      "    t = torch._utils._rebuild_tensor(storage, storage_offset, size, stride)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\torch\\_utils.py\", line 181, in _rebuild_tensor\n",
      "    return t.set_(storage._untyped_storage, storage_offset, size, stride)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-24 21:41:36,673] Trial 0 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'user_ft_ext_param'  'n_prototypes': 5,,\n",
    "'item_ft_ext_param' 'n_prototypes': 5,\n",
    " 'embedding_dim': 100,\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    prototypes1 = trial.suggest_int(\"prototypes1\", 20, 100, 20)\n",
    "    prototypes2 = trial.suggest_int(\"prototypes2\", 20, 100, 20)\n",
    "\n",
    "    embeddings_dim = trial.suggest_int(\"embedding_dim\", 50, 400, 50)\n",
    "\n",
    "    proto_double_tie_chose_original_hyper_params[\"ft_ext_param\"][\"user_ft_ext_param\"][\n",
    "        \"n_prototypes\"\n",
    "    ] = prototypes1\n",
    "    proto_double_tie_chose_original_hyper_params[\"ft_ext_param\"][\"item_ft_ext_param\"][\n",
    "        \"n_prototypes\"\n",
    "    ] = prototypes2\n",
    "    proto_double_tie_chose_original_hyper_params[\"embedding_dim\"] = embeddings_dim\n",
    "\n",
    "    config = argparse.Namespace(**proto_double_tie_chose_original_hyper_params)\n",
    "    data_loaders_dict = load_data(config)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        data_loaders_dict[\"train_loader\"], data_loaders_dict[\"val_loader\"], config\n",
    "    )\n",
    "\n",
    "    return trainer.run(trial)\n",
    "\n",
    "\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256be11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Optimization\n",
      "Seed is 38210573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 03:16:32,251\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "2023-12-24 03:16:34,005\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2023-12-24 03:16:34,011\tINFO tune.py:583 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-12-24 03:16:55</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:20.37        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.8/15.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0.4/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  NUM_WORKERS</th><th style=\"text-align: right;\">  batch_size</th><th>data_path           </th><th>device  </th><th>eval_neg_strategy  </th><th style=\"text-align: right;\">   ft_ext_param/embeddi\n",
       "ng_dim</th><th>ft_ext_param/ft_type  </th><th>...t_param/item_ft_e\n",
       "xt_param/cosine_type        </th><th>ft_ext_param/item_ft\n",
       "_ext_param/ft_type                     </th><th style=\"text-align: right;\">   ..._param/item_ft_ex\n",
       "t_param/n_prototypes</th><th>...aram/item_ft_ext_\n",
       "param/reg_batch_type    </th><th>...aram/item_ft_ext_\n",
       "param/reg_proto_type    </th><th style=\"text-align: right;\">          ...am/item_ft_ext_pa\n",
       "ram/sim_batch_weight</th><th style=\"text-align: right;\">          ...am/item_ft_ext_pa\n",
       "ram/sim_proto_weight</th><th>...m/item_ft_ext_par\n",
       "am/use_weight_matrix      </th><th>...t_param/user_ft_e\n",
       "xt_param/cosine_type        </th><th>ft_ext_param/user_ft\n",
       "_ext_param/ft_type                     </th><th style=\"text-align: right;\">   ..._param/user_ft_ex\n",
       "t_param/n_prototypes</th><th>...aram/user_ft_ext_\n",
       "param/reg_batch_type    </th><th>...aram/user_ft_ext_\n",
       "param/reg_proto_type    </th><th style=\"text-align: right;\">          ...am/user_ft_ext_pa\n",
       "ram/sim_batch_weight</th><th style=\"text-align: right;\">          ...am/user_ft_ext_pa\n",
       "ram/sim_proto_weight</th><th>...m/user_ft_ext_par\n",
       "am/use_weight_matrix      </th><th>loss_func_aggr  </th><th>loss_func_name  </th><th style=\"text-align: right;\">  n_epochs</th><th style=\"text-align: right;\">  neg_train</th><th style=\"text-align: right;\">  neg_val</th><th style=\"text-align: right;\">  optim_param/lr</th><th>optim_param/optim  </th><th style=\"text-align: right;\">  optim_param/wd</th><th style=\"text-align: right;\">  rec_sys_param/use_bi\n",
       "as</th><th style=\"text-align: right;\">    seed</th><th style=\"text-align: right;\">  train_batch_size</th><th>train_neg_strategy  </th><th style=\"text-align: right;\">  val_batch_size</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>ui model_ml_38210573_d61f3356</td><td>RUNNING </td><td>127.0.0.1:3464 </td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">         162</td><td>C:\\Users\\Alexey_c030</td><td>cuda    </td><td>uniform            </td><td style=\"text-align: right;\">55</td><td>prototypes_doub_a790  </td><td>shifted</td><td>prototypes_doub_a790</td><td style=\"text-align: right;\">92</td><td>max</td><td>max</td><td style=\"text-align: right;\">0.0512209</td><td style=\"text-align: right;\">6.08195  </td><td>False</td><td>shifted</td><td>prototypes_doub_a790</td><td style=\"text-align: right;\">70</td><td>max</td><td>max</td><td style=\"text-align: right;\">2.20496  </td><td style=\"text-align: right;\">0.0442315</td><td>False</td><td>mean            </td><td>sampled_softmax </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">         99</td><td style=\"text-align: right;\">       99</td><td style=\"text-align: right;\">       0.0661069</td><td>adagrad            </td><td style=\"text-align: right;\">      0.00226364</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">38210573</td><td style=\"text-align: right;\">               256</td><td>uniform             </td><td style=\"text-align: right;\">             256</td></tr>\n",
       "<tr><td>ui model_ml_38210573_4e9b67f9</td><td>RUNNING </td><td>127.0.0.1:29232</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">         162</td><td>C:\\Users\\Alexey_c030</td><td>cuda    </td><td>uniform            </td><td style=\"text-align: right;\">45</td><td>prototypes_doub_a790  </td><td>shifted</td><td>prototypes_doub_a790</td><td style=\"text-align: right;\">29</td><td>max</td><td>max</td><td style=\"text-align: right;\">1.47044  </td><td style=\"text-align: right;\">0.0934367</td><td>False</td><td>shifted</td><td>prototypes_doub_a790</td><td style=\"text-align: right;\">74</td><td>max</td><td>max</td><td style=\"text-align: right;\">0.0309485</td><td style=\"text-align: right;\">0.881004 </td><td>False</td><td>mean            </td><td>sampled_softmax </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">         99</td><td style=\"text-align: right;\">       99</td><td style=\"text-align: right;\">       0.0661069</td><td>adagrad            </td><td style=\"text-align: right;\">      0.00226364</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">38210573</td><td style=\"text-align: right;\">               256</td><td>uniform             </td><td style=\"text-align: right;\">             256</td></tr>\n",
       "<tr><td>ui model_ml_38210573_99b52469</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">         162</td><td>C:\\Users\\Alexey_c030</td><td>cuda    </td><td>uniform            </td><td style=\"text-align: right;\">94</td><td>prototypes_doub_a790  </td><td>shifted</td><td>prototypes_doub_a790</td><td style=\"text-align: right;\">87</td><td>max</td><td>max</td><td style=\"text-align: right;\">0.114407 </td><td style=\"text-align: right;\">0.0223808</td><td>False</td><td>shifted</td><td>prototypes_doub_a790</td><td style=\"text-align: right;\">67</td><td>max</td><td>max</td><td style=\"text-align: right;\">0.0305799</td><td style=\"text-align: right;\">5.93527  </td><td>False</td><td>mean            </td><td>sampled_softmax </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">         99</td><td style=\"text-align: right;\">       99</td><td style=\"text-align: right;\">       0.0661069</td><td>adagrad            </td><td style=\"text-align: right;\">      0.00226364</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">38210573</td><td style=\"text-align: right;\">               256</td><td>uniform             </td><td style=\"text-align: right;\">             256</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=3464)\u001b[0m c:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\n",
      "\u001b[36m(pid=3464)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\ray\\thirdparty_files\n",
      "\u001b[36m(pid=3464)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\ray\\_private\\workers\n",
      "\u001b[36m(pid=3464)\u001b[0m C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\python311.zip\n",
      "\u001b[36m(pid=3464)\u001b[0m C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\DLLs\n",
      "\u001b[36m(pid=3464)\u001b[0m C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\n",
      "\u001b[36m(pid=3464)\u001b[0m C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\n",
      "\u001b[36m(pid=3464)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\n",
      "\u001b[36m(pid=3464)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\n",
      "\u001b[36m(pid=3464)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\win32\n",
      "\u001b[36m(pid=3464)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\win32\\lib\n",
      "\u001b[36m(pid=3464)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\Pythonwin\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Namespace(loss_func_aggr='mean', ft_ext_param={'ft_type': 'prototypes_double_tie', 'embedding_dim': 55, 'item_ft_ext_param': {'ft_type': 'prototypes_double_tie', 'sim_proto_weight': 6.081951634103192, 'sim_batch_weight': 0.051220908176989904, 'use_weight_matrix': False, 'n_prototypes': 92, 'cosine_type': 'shifted', 'reg_proto_type': 'max', 'reg_batch_type': 'max'}, 'user_ft_ext_param': {'ft_type': 'prototypes_double_tie', 'sim_proto_weight': 0.04423150804510789, 'sim_batch_weight': 2.2049570820737068, 'use_weight_matrix': False, 'n_prototypes': 70, 'cosine_type': 'shifted', 'reg_proto_type': 'max', 'reg_batch_type': 'max'}}, device='cuda', n_epochs=1, eval_neg_strategy='uniform', val_batch_size=256, train_batch_size=256, data_path='C:\\\\Users\\\\Alexey\\\\Documents\\\\github\\\\hse_courses\\\\2nd_year\\\\term1\\\\recsys\\\\project\\\\ProtoMF\\\\data\\\\ml', NUM_WORKERS=1, rec_sys_param={'use_bias': 0}, neg_train=99, neg_val=99, train_neg_strategy='uniform', loss_func_name='sampled_softmax', batch_size=162, optim_param={'optim': 'adagrad', 'wd': 0.0022636354348984536, 'lr': 0.06610686700232844}, seed=38210573)\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Loading data\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built ProtoRecDataset module \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - data_path: C:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\\ProtoMF\\data\\ml \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_users: 6028 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_items: 3123 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_interactions: 545656 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - split_set: train \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_neg: 99 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - neg_strategy: uniform \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Loading data\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built ProtoRecDataset module \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - data_path: C:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\\ProtoMF\\data\\ml \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_users: 6028 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_items: 3123 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_interactions: 14196 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - split_set: val \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_neg: 99 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - neg_strategy: uniform \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Loading data\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built ProtoRecDataset module \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - data_path: C:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\\ProtoMF\\data\\ml \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_users: 6028 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_items: 3123 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_interactions: 13952 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - split_set: test \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_neg: 99 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - neg_strategy: uniform \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m --- Building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built Embedding model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_objects: 6028 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - embedding_dim: 55 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - max_norm: None\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - only_positive: False\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built PrototypeEmbedding model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_prototypes: 70 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - use_weight_matrix: False \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - sim_proto_weight: 0.04423150804510789 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - sim_batch_weight: 2.2049570820737068 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - reg_proto_type: max \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - reg_batch_type: max \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - cosine_type: shifted \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m --- Finished building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m --- Building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built Embedding model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_objects: 6028 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - embedding_dim: 55 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - max_norm: None\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - only_positive: False\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built Embeddingw model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - out_dimension: 92 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - use_bias: False \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m --- Finished building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m --- Building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built Embedding model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_objects: 3123 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - embedding_dim: 55 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - max_norm: None\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - only_positive: False\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built PrototypeEmbedding model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_prototypes: 92 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - use_weight_matrix: False \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - sim_proto_weight: 6.081951634103192 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - sim_batch_weight: 0.051220908176989904 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - reg_proto_type: max \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - reg_batch_type: max \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - cosine_type: shifted \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m --- Finished building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m --- Building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built Embedding model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_objects: 3123 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - embedding_dim: 55 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - max_norm: None\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - only_positive: False\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built Embeddingw model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - out_dimension: 70 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - use_bias: False \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m --- Finished building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built ConcatenateFeatureExtractors model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - model_1: PrototypeEmbedding \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - model_2: EmbeddingW \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - invert: False \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built ConcatenateFeatureExtractors model \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - model_1: PrototypeEmbedding \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - model_2: EmbeddingW \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - invert: True \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built RecSys module \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_users: 6028 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_items: 3123 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - user_feature_extractor: ConcatenateFeatureExtractors \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - item_feature_extractor: ConcatenateFeatureExtractors \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - loss_func_name: sampled_softmax \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - use_bias: False \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built Optimizer  \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - name: adagrad \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - lr: 0.06610686700232844 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - wd: 0.0022636354348984536 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Built Trainer module \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - n_epochs: 1 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - loss_func_name: sampled_softmax \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - loss_func_aggr: mean \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - device: cuda \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m - optimizing_metric: hit_ratio@10 \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m \n",
      "\u001b[36m(start_training pid=3464)\u001b[0m Validation started\n",
      "\u001b[36m(pid=29232)\u001b[0m c:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\n",
      "\u001b[36m(pid=29232)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\ray\\thirdparty_files\n",
      "\u001b[36m(pid=29232)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\ray\\_private\\workers\n",
      "\u001b[36m(pid=29232)\u001b[0m C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\python311.zip\n",
      "\u001b[36m(pid=29232)\u001b[0m C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\DLLs\n",
      "\u001b[36m(pid=29232)\u001b[0m C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\n",
      "\u001b[36m(pid=29232)\u001b[0m C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\n",
      "\u001b[36m(pid=29232)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\n",
      "\u001b[36m(pid=29232)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\n",
      "\u001b[36m(pid=29232)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\win32\n",
      "\u001b[36m(pid=29232)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\win32\\lib\n",
      "\u001b[36m(pid=29232)\u001b[0m c:\\Users\\Alexey\\venvs\\recsys_project\\Lib\\site-packages\\Pythonwin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_WandbLoggingActor pid=27252)\u001b[0m wandb: Currently logged in as: ras-unlucky (rho-corp). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(start_training pid=29232)\u001b[0m Namespace(loss_func_aggr='mean', ft_ext_param={'ft_type': 'prototypes_double_tie', 'embedding_dim': 45, 'item_ft_ext_param': {'ft_type': 'prototypes_double_tie', 'sim_proto_weight': 0.09343665856284789, 'sim_batch_weight': 1.4704425396918077, 'use_weight_matrix': False, 'n_prototypes': 29, 'cosine_type': 'shifted', 'reg_proto_type': 'max', 'reg_batch_type': 'max'}, 'user_ft_ext_param': {'ft_type': 'prototypes_double_tie', 'sim_proto_weight': 0.8810036892287099, 'sim_batch_weight': 0.030948521969642345, 'use_weight_matrix': False, 'n_prototypes': 74, 'cosine_type': 'shifted', 'reg_proto_type': 'max', 'reg_batch_type': 'max'}}, device='cuda', n_epochs=1, eval_neg_strategy='uniform', val_batch_size=256, train_batch_size=256, data_path='C:\\\\Users\\\\Alexey\\\\Documents\\\\github\\\\hse_courses\\\\2nd_year\\\\term1\\\\recsys\\\\project\\\\ProtoMF\\\\data\\\\ml', NUM_WORKERS=1, rec_sys_param={'use_bias': 0}, neg_train=99, neg_val=99, train_neg_strategy='uniform', loss_func_name='sampled_softmax', batch_size=162, optim_param={'optim': 'adagrad', 'wd': 0.0022636354348984536, 'lr': 0.06610686700232844}, seed=38210573)\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Loading data\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built ProtoRecDataset module \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - data_path: C:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\\ProtoMF\\data\\ml \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_users: 6028 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_items: 3123 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_interactions: 545656 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - split_set: train \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_neg: 99 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - neg_strategy: uniform \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Loading data\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built ProtoRecDataset module \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - data_path: C:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\\ProtoMF\\data\\ml \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_users: 6028 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_items: 3123 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_interactions: 14196 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - split_set: val \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_neg: 99 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - neg_strategy: uniform \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_WandbLoggingActor pid=27252)\u001b[0m wandb: Tracking run with wandb version 0.16.1\n",
      "\u001b[36m(_WandbLoggingActor pid=27252)\u001b[0m wandb: Run data is saved locally in C:\\Users\\Alexey\\ray_results\\ui model_ml_38210573_2023-12-24_3-16-29.780734\\ui model_ml_38210573_d61f3356_1_NUM_WORKERS=1,batch_size=162,data_path=C_Users_Alexey_Documents_github_hse_courses_2nd_year_term1__2023-12-24_03-16-34\\wandb\\run-20231224_031645-d61f3356\n",
      "\u001b[36m(_WandbLoggingActor pid=27252)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36m(_WandbLoggingActor pid=27252)\u001b[0m wandb: Syncing run ui model_ml_38210573_d61f3356\n",
      "\u001b[36m(_WandbLoggingActor pid=27252)\u001b[0m wandb:  View project at https://wandb.ai/rho-corp/protomf\n",
      "\u001b[36m(_WandbLoggingActor pid=27252)\u001b[0m wandb:  View run at https://wandb.ai/rho-corp/protomf/runs/d61f3356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(start_training pid=29232)\u001b[0m Built ProtoRecDataset module \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - data_path: C:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\\ProtoMF\\data\\ml \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_users: 6028 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_items: 3123 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_interactions: 13952 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - split_set: test \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_neg: 99 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - neg_strategy: uniform \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m --- Building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built Embedding model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_objects: 6028 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - embedding_dim: 45 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - max_norm: None\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - only_positive: False\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built PrototypeEmbedding model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_prototypes: 74 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - use_weight_matrix: False \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - sim_proto_weight: 0.8810036892287099 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - sim_batch_weight: 0.030948521969642345 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - reg_proto_type: max \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - reg_batch_type: max \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - cosine_type: shifted \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m --- Finished building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m --- Building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built Embedding model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_objects: 6028 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - embedding_dim: 45 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - max_norm: None\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - only_positive: False\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built Embeddingw model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - out_dimension: 29 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - use_bias: False \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m --- Finished building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m --- Building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built Embedding model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_objects: 3123 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - embedding_dim: 45 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - max_norm: None\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - only_positive: False\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built PrototypeEmbedding model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_prototypes: 29 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - use_weight_matrix: False \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - sim_proto_weight: 0.09343665856284789 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - sim_batch_weight: 1.4704425396918077 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - reg_proto_type: max \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - reg_batch_type: max \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - cosine_type: shifted \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m --- Finished building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m --- Building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built Embedding model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_objects: 3123 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - embedding_dim: 45 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - max_norm: None\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - only_positive: False\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built Embeddingw model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - out_dimension: 74 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - use_bias: False \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m --- Finished building FeatureExtractor model ---\n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built ConcatenateFeatureExtractors model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - model_1: PrototypeEmbedding \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - model_2: EmbeddingW \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - invert: False \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built ConcatenateFeatureExtractors model \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - model_1: PrototypeEmbedding \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - model_2: EmbeddingW \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - invert: True \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built RecSys module \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_users: 6028 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_items: 3123 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - user_feature_extractor: ConcatenateFeatureExtractors \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - item_feature_extractor: ConcatenateFeatureExtractors \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - loss_func_name: sampled_softmax \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - use_bias: False \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - loss_func_name: sampled_softmax \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built Optimizer  \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - name: adagrad \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - lr: 0.06610686700232844 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - wd: 0.0022636354348984536 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Built Trainer module \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - n_epochs: 1 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - loss_func_aggr: mean \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - device: cuda \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m - optimizing_metric: hit_ratio@10 \n",
      "\u001b[36m(start_training pid=29232)\u001b[0m Validation started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb: Currently logged in as: ras-unlucky (rho-corp). Use `wandb login --relogin` to force relogin\n",
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb: | Waiting for wandb.init()...\n",
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb: Tracking run with wandb version 0.16.1\n",
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb: Run data is saved locally in C:\\Users\\Alexey\\ray_results\\ui model_ml_38210573_2023-12-24_3-16-29.780734\\ui model_ml_38210573_4e9b67f9_2_NUM_WORKERS=1,batch_size=162,data_path=C_Users_Alexey_Documents_github_hse_courses_2nd_year_term1__2023-12-24_03-16-39\\wandb\\run-20231224_031656-4e9b67f9\n",
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb: Syncing run ui model_ml_38210573_4e9b67f9\n",
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb:  View project at https://wandb.ai/rho-corp/protomf\n",
      "\u001b[36m(_WandbLoggingActor pid=2716)\u001b[0m wandb:  View run at https://wandb.ai/rho-corp/protomf/runs/4e9b67f9\n"
     ]
    }
   ],
   "source": [
    "start_hyper(proto_double_tie_chose_original_hyper_params, \"ui model\", \"ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a21805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        n_items: int,\n",
    "        rec_sys_param,\n",
    "        user_feature_extractor: FeatureExtractor,\n",
    "        item_feature_extractor: FeatureExtractor,\n",
    "        loss_func_name: str,\n",
    "        loss_func_aggr: str = \"mean\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        General Recommender System\n",
    "        It generates the user/item vectors (given the feature extractors) and computes the similarity by the dot product.\n",
    "        :param n_users: number of users in the system\n",
    "        :param n_items: number of items in the system\n",
    "        :param rec_sys_param: parameters of the Recommender System module\n",
    "        :param user_feature_extractor: feature_extractor.FeatureExtractor module that generates user embeddings.\n",
    "        :param item_feature_extractor: feature_extractor.FeatureExtractor module that generates item embeddings.\n",
    "        :param loss_func_name: name of the loss function to use for the network.\n",
    "        :param loss_func_aggr: type of aggregation for the loss function, either 'mean' or 'sum'.\n",
    "        \"\"\"\n",
    "\n",
    "        assert loss_func_aggr in [\n",
    "            \"mean\",\n",
    "            \"sum\",\n",
    "        ], f\"Loss function aggregators <{loss_func_aggr}> not implemented...yet\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.rec_sys_param = rec_sys_param\n",
    "        self.user_feature_extractor = user_feature_extractor\n",
    "        self.item_feature_extractor = item_feature_extractor\n",
    "        self.loss_func_name = loss_func_name\n",
    "        self.loss_func_aggr = loss_func_aggr\n",
    "\n",
    "        self.use_bias = (\n",
    "            self.rec_sys_param[\"use_bias\"] > 0\n",
    "            if \"use_bias\" in self.rec_sys_param\n",
    "            else True\n",
    "        )\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.user_bias = nn.Embedding(self.n_users, 1)\n",
    "            self.item_bias = nn.Embedding(self.n_items, 1)\n",
    "            self.global_bias = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "        if self.loss_func_name == \"bce\":\n",
    "            self.rec_loss = partial(bce_loss, aggregator=self.loss_func_aggr)\n",
    "        elif self.loss_func_name == \"bpr\":\n",
    "            self.rec_loss = partial(bpr_loss, aggregator=self.loss_func_aggr)\n",
    "        elif self.loss_func_name == \"sampled_softmax\":\n",
    "            self.rec_loss = partial(\n",
    "                sampled_softmax_loss, aggregator=self.loss_func_aggr\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Recommender System Loss function <{self.rec_loss}> Not Implemented... Yet\"\n",
    "            )\n",
    "\n",
    "        self.initialized = False\n",
    "\n",
    "        print(\n",
    "            f\"Built RecSys module \\n\"\n",
    "            f\"- n_users: {self.n_users} \\n\"\n",
    "            f\"- n_items: {self.n_items} \\n\"\n",
    "            f\"- user_feature_extractor: {self.user_feature_extractor.name} \\n\"\n",
    "            f\"- item_feature_extractor: {self.item_feature_extractor.name} \\n\"\n",
    "            f\"- loss_func_name: {self.loss_func_name} \\n\"\n",
    "            f\"- use_bias: {self.use_bias} \\n\"\n",
    "        )\n",
    "\n",
    "    def init_parameters(self):\n",
    "        \"\"\"\n",
    "        Method for initializing the Recommender System Processor\n",
    "        \"\"\"\n",
    "        if self.use_bias:\n",
    "            torch.nn.init.constant_(self.user_bias.weight, 0.0)\n",
    "            torch.nn.init.constant_(self.item_bias.weight, 0.0)\n",
    "\n",
    "        self.user_feature_extractor.init_parameters()\n",
    "        self.item_feature_extractor.init_parameters()\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def loss_func(self, logits, labels):\n",
    "        \"\"\"\n",
    "        Loss function of the Recommender System module. It takes into account eventual feature_extractor loss terms.\n",
    "        NB. Any feature_extractor loss is pre-weighted.\n",
    "        :param logits: output of the system.\n",
    "        :param labels: binary labels\n",
    "        :return: aggregated loss\n",
    "        \"\"\"\n",
    "\n",
    "        rec_loss = self.rec_loss(logits, labels)\n",
    "        item_feat_ext_loss = self.item_feature_extractor.get_and_reset_loss()\n",
    "        user_feat_ext_loss = self.user_feature_extractor.get_and_reset_loss()\n",
    "        return rec_loss + item_feat_ext_loss + user_feat_ext_loss\n",
    "\n",
    "    def forward(self, u_idxs, i_idxs):\n",
    "        \"\"\"\n",
    "        Performs the forward pass considering user indexes and the item indexes. Negative Sampling is done automatically\n",
    "        by the dataloader\n",
    "        :param u_idxs: User indexes. Shape is (batch_size,)\n",
    "        :param i_idxs: Item indexes. Shape is (batch_size, n_neg + 1)\n",
    "\n",
    "        :return: A matrix of logits values. Shape is (batch_size, 1 + n_neg). First column is always associated\n",
    "                to the positive track.\n",
    "        \"\"\"\n",
    "        assert self.initialized, (\n",
    "            \"Model initialization has not been called! Please call .init_parameters() \"\n",
    "            \"before using the model\"\n",
    "        )\n",
    "\n",
    "        # --- User pass ---\n",
    "        u_embed = self.user_feature_extractor(u_idxs)\n",
    "        if self.use_bias:\n",
    "            u_bias = self.user_bias(u_idxs)\n",
    "\n",
    "        # --- Item pass ---\n",
    "        if self.use_bias:\n",
    "            i_bias = self.item_bias(i_idxs).squeeze()\n",
    "\n",
    "        i_embed = self.item_feature_extractor(i_idxs)\n",
    "\n",
    "        # --- Dot Product ---\n",
    "        dots = torch.sum(\n",
    "            u_embed.unsqueeze(1) * i_embed, dim=-1\n",
    "        )  # [batch_size, n_neg_p_1]\n",
    "\n",
    "        if self.use_bias:\n",
    "            # Optional bias\n",
    "            dots = dots + u_bias + i_bias + self.global_bias\n",
    "\n",
    "        return dots\n",
    "\n",
    "\n",
    "def bce_loss(logits, labels, aggregator=\"mean\"):\n",
    "    \"\"\"\n",
    "    It computes the binary cross entropy loss with negative sampling, expressed by the formula:\n",
    "                                    -_j log(x_ui) + log(1 - x_uj)\n",
    "    where x_ui and x_uj are the prediction for user u on item i and j, respectively. Item i positive instance while\n",
    "    Item j is a negative instance. The Sum is carried out across the different negative instances. In other words\n",
    "    the positive item is weighted as many as negative items are considered.\n",
    "\n",
    "    :param logits: Logits values from the network. The first column always contain the values of positive instances.\n",
    "            Shape is (batch_size, 1 + n_neg).\n",
    "    :param labels: 1-0 Labels. The first column contains 1s while all the others 0s.\n",
    "    :param aggregator: function to use to aggregate the loss terms. Default to mean\n",
    "\n",
    "    :return: The binary cross entropy as computed above\n",
    "    \"\"\"\n",
    "    weights = torch.ones_like(logits)\n",
    "    weights[:, 0] = logits.shape[1] - 1\n",
    "\n",
    "    loss = nn.BCEWithLogitsLoss(weights.flatten(), reduction=aggregator)(\n",
    "        logits.flatten(), labels.flatten()\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bpr_loss(logits, labels, aggregator=\"mean\"):\n",
    "    \"\"\"\n",
    "    It computes the Bayesian Personalized Ranking loss (https://arxiv.org/pdf/1205.2618.pdf).\n",
    "\n",
    "    :param logits: Logits values from the network. The first column always contain the values of positive instances.\n",
    "            Shape is (batch_size, 1 + n_neg).\n",
    "    :param labels: 1-0 Labels. The first column contains 1s while all the others 0s.\n",
    "    :param aggregator: function to use to aggregate the loss terms. Default to mean\n",
    "\n",
    "    :return: The bayesian personalized ranking loss\n",
    "    \"\"\"\n",
    "    pos_logits = logits[:, 0].unsqueeze(1)  # [batch_size,1]\n",
    "    neg_logits = logits[:, 1:]  # [batch_size,n_neg]\n",
    "\n",
    "    labels = labels[:, 0]  # I guess this is just to avoid problems with the device\n",
    "    labels = torch.repeat_interleave(labels, neg_logits.shape[1])\n",
    "\n",
    "    diff_logits = pos_logits - neg_logits\n",
    "\n",
    "    loss = nn.BCEWithLogitsLoss(reduction=aggregator)(\n",
    "        diff_logits.flatten(), labels.flatten()\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def sampled_softmax_loss(logits, labels, aggregator=\"sum\"):\n",
    "    \"\"\"\n",
    "    It computes the (Sampled) Softmax Loss (a.k.a. sampled cross entropy) expressed by the formula:\n",
    "                        -x_ui +  log( _j e^{x_uj})\n",
    "    where x_ui and x_uj are the prediction for user u on item i and j, respectively. Item i positive instance while j\n",
    "    goes over all the sampled items (negatives + the positive).\n",
    "    :param logits: Logits values from the network. The first column always contain the values of positive instances.\n",
    "            Shape is (batch_size, 1 + n_neg).\n",
    "    :param labels: 1-0 Labels. The first column contains 1s while all the others 0s.\n",
    "    :param aggregator: function to use to aggregate the loss terms. Default to sum\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    pos_logits_sum = -logits[:, 0]\n",
    "    log_sum_exp_sum = torch.logsumexp(logits, dim=-1)\n",
    "\n",
    "    sampled_loss = pos_logits_sum + log_sum_exp_sum\n",
    "\n",
    "    if aggregator == \"sum\":\n",
    "        return sampled_loss.sum()\n",
    "    elif aggregator == \"mean\":\n",
    "        return sampled_loss.mean()\n",
    "    else:\n",
    "        raise ValueError(\"Loss aggregator not defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96812ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = Path(\"./ProtoMF/best_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f30b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, train_loader: data.DataLoader, val_loader: data.DataLoader, conf\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train and Evaluate the model.\n",
    "        :param train_loader: Training DataLoader (check music4all_data.Music4AllDataset for more info)\n",
    "        :param val_loader: Validation DataLoader (check music4all_data.Music4AllDataset for more info)\n",
    "        :param conf: Experiment configuration parameters\n",
    "        \"\"\"\n",
    "\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "        self.rec_sys_param = conf.rec_sys_param\n",
    "        self.ft_ext_param = conf.ft_ext_param\n",
    "        self.optim_param = conf.optim_param\n",
    "\n",
    "        self.n_epochs = conf.n_epochs\n",
    "        self.loss_func_name = conf.loss_func_name\n",
    "        self.loss_func_aggr = (\n",
    "            conf.loss_func_aggr if \"loss_func_aggr\" in conf else \"mean\"\n",
    "        )\n",
    "\n",
    "        self.device = conf.device\n",
    "\n",
    "        self.optimizing_metric = OPTIMIZING_METRIC\n",
    "        self.max_patience = MAX_PATIENCE\n",
    "\n",
    "        self.model = self._build_model()\n",
    "        self.optimizer = self._build_optimizer()\n",
    "\n",
    "        print(\n",
    "            f\"Built Trainer module \\n\"\n",
    "            f\"- n_epochs: {self.n_epochs} \\n\"\n",
    "            f\"- loss_func_name: {self.loss_func_name} \\n\"\n",
    "            f\"- loss_func_aggr: {self.loss_func_aggr} \\n\"\n",
    "            f\"- device: {self.device} \\n\"\n",
    "            f\"- optimizing_metric: {self.optimizing_metric} \\n\"\n",
    "        )\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Step 1 --- Building User and Item Feature Extractors\n",
    "        n_users = self.train_loader.dataset.n_users\n",
    "        n_items = self.train_loader.dataset.n_items\n",
    "        (\n",
    "            user_feature_extractor,\n",
    "            item_feature_extractor,\n",
    "        ) = FeatureExtractorFactory.create_models(self.ft_ext_param, n_users, n_items)\n",
    "        # Step 2 --- Building RecSys Module\n",
    "        rec_sys = RecSys(\n",
    "            n_users,\n",
    "            n_items,\n",
    "            self.rec_sys_param,\n",
    "            user_feature_extractor,\n",
    "            item_feature_extractor,\n",
    "            self.loss_func_name,\n",
    "            self.loss_func_aggr,\n",
    "        )\n",
    "\n",
    "        rec_sys.init_parameters()\n",
    "        rec_sys = nn.DataParallel(rec_sys)\n",
    "        rec_sys = rec_sys.to(self.device)\n",
    "\n",
    "        return rec_sys\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        self.lr = self.optim_param[\"lr\"] if \"lr\" in self.optim_param else 1e-3\n",
    "        self.wd = self.optim_param[\"wd\"] if \"wd\" in self.optim_param else 1e-4\n",
    "\n",
    "        optim_name = self.optim_param[\"optim\"]\n",
    "        if optim_name == \"adam\":\n",
    "            optim = torch.optim.Adam(\n",
    "                self.model.parameters(), lr=self.lr, weight_decay=self.wd\n",
    "            )\n",
    "        elif optim_name == \"adagrad\":\n",
    "            optim = torch.optim.Adagrad(\n",
    "                self.model.parameters(), lr=self.lr, weight_decay=self.wd\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Optimizer not yet included\")\n",
    "\n",
    "        print(\n",
    "            f\"Built Optimizer  \\n\"\n",
    "            f\"- name: {optim_name} \\n\"\n",
    "            f\"- lr: {self.lr} \\n\"\n",
    "            f\"- wd: {self.wd} \\n\"\n",
    "        )\n",
    "\n",
    "        return optim\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the Training procedure\n",
    "        \"\"\"\n",
    "        metrics_values = self.val()\n",
    "        best_value = metrics_values[self.optimizing_metric]\n",
    "        #         tune.report(metrics_values)\n",
    "        print(\"Init - Avg Val Value {:.3f} \\n\".format(best_value))\n",
    "\n",
    "        patience = 0\n",
    "        for epoch in range(self.n_epochs):\n",
    "            if patience == self.max_patience:\n",
    "                print(\"Max Patience reached, stopping.\")\n",
    "                break\n",
    "\n",
    "            self.model.train()\n",
    "\n",
    "            epoch_train_loss = 0\n",
    "\n",
    "            for u_idxs, i_idxs, labels in self.train_loader:\n",
    "                u_idxs = u_idxs.to(self.device)\n",
    "                i_idxs = i_idxs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                out = self.model(u_idxs, i_idxs)\n",
    "\n",
    "                loss = self.model.module.loss_func(out, labels)\n",
    "\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                if int(u_idxs[0]) % 1000 == 0:\n",
    "                    print(str(int(u_idxs[0])) + \"_users_past\")\n",
    "            epoch_train_loss /= len(self.train_loader)\n",
    "            print(\n",
    "                \"Epoch {} - Epoch Avg Train Loss {:.3f} \\n\".format(\n",
    "                    epoch, epoch_train_loss\n",
    "                )\n",
    "            )\n",
    "\n",
    "            metrics_values = self.val()\n",
    "            curr_value = metrics_values[self.optimizing_metric]\n",
    "            print(\"Epoch {} - Avg Val Value {:.3f} \\n\".format(epoch, curr_value))\n",
    "            tune.report({**metrics_values, \"epoch_train_loss\": epoch_train_loss})\n",
    "\n",
    "            if curr_value > best_value:\n",
    "                best_value = curr_value\n",
    "                print(\n",
    "                    \"Epoch {} - New best model found (val value {:.3f}) \\n\".format(\n",
    "                        epoch, curr_value\n",
    "                    )\n",
    "                )\n",
    "                torch.save(\n",
    "                    self.model.module.state_dict(),\n",
    "                    os.path.join(checkpoint_dir, \"best_model.pth\"),\n",
    "                )\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience += 1\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def val(self):\n",
    "        \"\"\"\n",
    "        Runs the evaluation procedure.\n",
    "        :return: A scalar float value, output of the validation (e.g. NDCG@10).\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        print(\"Validation started\")\n",
    "        val_loss = 0\n",
    "        eval = Evaluator(self.val_loader.dataset.n_users)\n",
    "\n",
    "        for u_idxs, i_idxs, labels in self.val_loader:\n",
    "            u_idxs = u_idxs.to(self.device)\n",
    "            i_idxs = i_idxs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            out = self.model(u_idxs, i_idxs)\n",
    "\n",
    "            val_loss += self.model.module.loss_func(out, labels).item()\n",
    "\n",
    "            out = nn.Sigmoid()(out)\n",
    "            out = out.to(\"cpu\")\n",
    "\n",
    "            eval.eval_batch(out)\n",
    "            if int(u_idxs[0]) % 1000 == 0:\n",
    "                print(str(int(u_idxs[0])) + \"_users_past\")\n",
    "        val_loss /= len(self.val_loader)\n",
    "        metrics_values = {**eval.get_results(), \"val_loss\": val_loss}\n",
    "\n",
    "        return metrics_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1b2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoRecDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class to be used in ProtoRec. To use this class for any dataset, please refer to the splitter functions\n",
    "    (e.g. movielens_splitter.py)\n",
    "\n",
    "    This class implements some basic functionalities about negative sampling. The negative sampling for a specific user\n",
    "    is influenced by the split_set:\n",
    "        - split_set = train: The other training items are excluded from the sampling.\n",
    "        - split_set = val: The other validation items and training items are excluded from the sampling.\n",
    "        - split_set = test: The other test items and training items are excluded from the sampling.\n",
    "\n",
    "    About the data management and access:\n",
    "    To perform a fast iteration and sampling over the dataset, we use two sparse matrices (COO and CSR). The COO\n",
    "    is used for iteration over the training data while the CSR for fast negative sampling. We always load the train\n",
    "    CSR since it is used to exclude the training data from the negative sampling also for Validation and Testing.\n",
    "    NB. Depending on the split_set, the matrices may have different data. Train COO and Train CSR have always the\n",
    "    same data. However, Val CSR has Val + Train data (same applies for test). This is due to the negative sampling\n",
    "    in the csr matrix, for which we also exclude items from training (see below).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, data_path: str, split_set: str, n_neg: int, neg_strategy: str = \"uniform\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param data_path: path to the directory with the listening_history_*, item_ids, and user_ids files.\n",
    "        :param split_set: Value in [train, val, test].\n",
    "        :param n_neg: Number of negative samples.\n",
    "        :param neg_strategy: Strategy to select the negative samples.\n",
    "        \"\"\"\n",
    "        assert split_set in [\n",
    "            \"train\",\n",
    "            \"val\",\n",
    "            \"test\",\n",
    "        ], f\"<{split_set}> is not a valid value for split set!\"\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.split_set = split_set\n",
    "        self.n_neg = n_neg\n",
    "        self.neg_strategy = neg_strategy\n",
    "\n",
    "        self.n_users = None\n",
    "        self.n_items = None\n",
    "\n",
    "        self.item_ids = None\n",
    "\n",
    "        self.coo_matrix = None\n",
    "        self.csr_matrix = None\n",
    "\n",
    "        self.pop_distribution = None\n",
    "\n",
    "        self.load_data()\n",
    "\n",
    "        print(\n",
    "            f\"Built ProtoRecDataset module \\n\"\n",
    "            f\"- data_path: {self.data_path} \\n\"\n",
    "            f\"- n_users: {self.n_users} \\n\"\n",
    "            f\"- n_items: {self.n_items} \\n\"\n",
    "            f\"- n_interactions: {self.coo_matrix.nnz} \\n\"\n",
    "            f\"- split_set: {self.split_set} \\n\"\n",
    "            f\"- n_neg: {self.n_neg} \\n\"\n",
    "            f\"- neg_strategy: {self.neg_strategy} \\n\"\n",
    "        )\n",
    "\n",
    "    def load_data(self):\n",
    "        print(\"Loading data\")\n",
    "\n",
    "        user_ids = pd.read_csv(os.path.join(self.data_path, \"user_ids.csv\"))\n",
    "        item_ids = pd.read_csv(os.path.join(self.data_path, \"item_ids.csv\"))\n",
    "\n",
    "        self.n_users = len(user_ids)\n",
    "        self.n_items = len(item_ids)\n",
    "\n",
    "        train_lhs = pd.read_csv(\n",
    "            os.path.join(self.data_path, \"listening_history_train.csv\")\n",
    "        )\n",
    "\n",
    "        train_csr = sp.csr_matrix(\n",
    "            (\n",
    "                np.ones(len(train_lhs), dtype=np.int16),\n",
    "                (train_lhs.user_id, train_lhs.item_id),\n",
    "            ),\n",
    "            shape=(self.n_users, self.n_items),\n",
    "        )\n",
    "\n",
    "        # Computing the popularity distribution (see _neg_sample_popular)\n",
    "        item_popularity = np.array(train_csr.sum(axis=0)).flatten()\n",
    "        self.pop_distribution = item_popularity / item_popularity.sum()\n",
    "\n",
    "        if self.split_set == \"val\":\n",
    "            val_lhs = pd.read_csv(\n",
    "                os.path.join(self.data_path, \"listening_history_val.csv\")\n",
    "            )\n",
    "\n",
    "            val_csr = sp.csr_matrix(\n",
    "                (\n",
    "                    np.ones(len(val_lhs), dtype=np.int16),\n",
    "                    (val_lhs.user_id, val_lhs.item_id),\n",
    "                ),\n",
    "                shape=(self.n_users, self.n_items),\n",
    "            )\n",
    "\n",
    "            val_coo = sp.coo_matrix(val_csr)\n",
    "\n",
    "            self.coo_matrix = val_coo\n",
    "            self.csr_matrix = val_csr + train_csr\n",
    "\n",
    "        elif self.split_set == \"test\":\n",
    "            test_lhs = pd.read_csv(\n",
    "                os.path.join(self.data_path, \"listening_history_test.csv\")\n",
    "            )\n",
    "\n",
    "            test_csr = sp.csr_matrix(\n",
    "                (\n",
    "                    np.ones(len(test_lhs), dtype=np.int16),\n",
    "                    (test_lhs.user_id, test_lhs.item_id),\n",
    "                ),\n",
    "                shape=(self.n_users, self.n_items),\n",
    "            )\n",
    "\n",
    "            test_coo = sp.coo_matrix(test_csr)\n",
    "\n",
    "            self.coo_matrix = test_coo\n",
    "            self.csr_matrix = test_csr + train_csr\n",
    "\n",
    "        elif self.split_set == \"train\":\n",
    "            train_coo = sp.coo_matrix(train_csr)\n",
    "\n",
    "            self.coo_matrix = train_coo\n",
    "            self.csr_matrix = train_csr\n",
    "\n",
    "    def _neg_sample_uniform(self, row_idx: int) -> np.array:\n",
    "        \"\"\"\n",
    "        For a specific user, it samples n_neg items u.a.r.\n",
    "        :param row_idx: user id (or row in the matrix)\n",
    "        :return: npy array containing the negatively sampled items.\n",
    "        \"\"\"\n",
    "\n",
    "        consumed_items = self.csr_matrix.indices[\n",
    "            self.csr_matrix.indptr[row_idx] : self.csr_matrix.indptr[row_idx + 1]\n",
    "        ]\n",
    "\n",
    "        # Uniform distribution without items consumed by the user\n",
    "        p = np.ones(self.n_items)\n",
    "        p[consumed_items] = 0.0  # Excluding consumed items\n",
    "        p = p / p.sum()\n",
    "\n",
    "        sampled = np.random.choice(\n",
    "            np.arange(self.n_items), self.n_neg, replace=False, p=p\n",
    "        )\n",
    "\n",
    "        return sampled\n",
    "\n",
    "    def _neg_sample_popular(self, row_idx: int) -> np.array:\n",
    "        \"\"\"\n",
    "        For a specific user, it samples n_neg items considering the frequency of appearance of items in the dataset, i.e.\n",
    "        p(i being neg)  (pop_i)^0.75.\n",
    "        :param row_idx: user id (or row in the matrix)\n",
    "        :return: npy array containing the negatively sampled items.\n",
    "        \"\"\"\n",
    "        consumed_items = self.csr_matrix.indices[\n",
    "            self.csr_matrix.indptr[row_idx] : self.csr_matrix.indptr[row_idx + 1]\n",
    "        ]\n",
    "\n",
    "        p = self.pop_distribution.copy()\n",
    "        p[consumed_items] = 0.0  # Excluding consumed items\n",
    "        p = np.power(p, 0.75)  # Squashing factor alpha = .75\n",
    "        p = p / p.sum()\n",
    "\n",
    "        sampled = np.random.choice(\n",
    "            np.arange(self.n_items), self.n_neg, replace=False, p=p\n",
    "        )\n",
    "        return sampled\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.coo_matrix.nnz\n",
    "\n",
    "    def __getitem__(self, index) -> T_co:\n",
    "        \"\"\"\n",
    "        Loads the (user,item) pair associated to the index and performs the negative sampling.\n",
    "        :param index: (user,item) index pair (as defined by the COO.data vector)\n",
    "        :return: (user_idx,item_idxs,labels) where\n",
    "            user_idx: is the index of the user\n",
    "            item_idxs: is a npy array containing the items indexes. The positive item is in the 1st position followed\n",
    "                        by the negative items indexes. Shape is (1 + n_neg,)\n",
    "            labels: npy array containing the labels. First position is 1, the others are 0. Shape is (1 + n_neg,).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        user_idx = self.coo_matrix.row[index].astype(\"int64\")\n",
    "        item_idx_pos = self.coo_matrix.col[index]\n",
    "\n",
    "        # Select the correct negative sampling strategy\n",
    "        if self.neg_strategy == \"uniform\":\n",
    "            neg_samples = self._neg_sample_uniform(user_idx)\n",
    "        elif self.neg_strategy == \"popular\":\n",
    "            neg_samples = self._neg_sample_popular(user_idx)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Negative Sampling Strategy <{self.neg_strategy}> not implemented ... Yet\"\n",
    "            )\n",
    "\n",
    "        item_idxs = np.concatenate(([item_idx_pos], neg_samples)).astype(\"int64\")\n",
    "\n",
    "        labels = np.zeros(1 + self.n_neg, dtype=\"float32\")\n",
    "        labels[0] = 1.0\n",
    "\n",
    "        return user_idx, item_idxs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6bd828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Built ProtoRecDataset module \n",
      "- data_path: ProtoMF\\data\\ml \n",
      "- n_users: 6028 \n",
      "- n_items: 3123 \n",
      "- n_interactions: 545656 \n",
      "- split_set: train \n",
      "- n_neg: 10 \n",
      "- neg_strategy: uniform \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " array([ 222,  994,  840,  175, 1634, 1579, 1230, 2104, 2736, 1697, 2827],\n",
       "       dtype=int64),\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(r\".\\ProtoMF\\data\\ml\")\n",
    "dataset = \"ml\"\n",
    "tst = ProtoRecDataset(data_path, \"train\", 10, \"uniform\")\n",
    "tst.__getitem__(0)\n",
    "tst2 = data.DataLoader(tst)\n",
    "tst2\n",
    "\n",
    "tst.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e93f4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protorecdataset_dataloader(\n",
    "    data_path: str, split_set: str, n_neg: int, neg_strategy=\"uniform\", **loader_params\n",
    ") -> data.DataLoader:\n",
    "    \"\"\"\n",
    "    Returns the dataloader for a ProtoRecDataset\n",
    "    :param data_path, ... ,neg_strategy: check ProtoRecDataset class for info about these parameters\n",
    "    :param loader_params: parameters for the Dataloader\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    protorec_dataset = ProtoRecDataset(data_path, split_set, n_neg, neg_strategy)\n",
    "    return data.DataLoader(protorec_dataset, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b296c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(conf, is_train: bool = True):\n",
    "    if is_train:\n",
    "        train_loader = get_protorecdataset_dataloader(\n",
    "            data_path=conf.data_path,\n",
    "            split_set=\"train\",\n",
    "            n_neg=conf.neg_train,\n",
    "            neg_strategy=conf.train_neg_strategy,\n",
    "            batch_size=conf.train_batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=conf.NUM_WORKERS,\n",
    "            prefetch_factor=5,\n",
    "        )\n",
    "\n",
    "        val_loader = get_protorecdataset_dataloader(\n",
    "            data_path=conf.data_path,\n",
    "            split_set=\"val\",\n",
    "            n_neg=conf.neg_val,\n",
    "            neg_strategy=conf.eval_neg_strategy,\n",
    "            batch_size=conf.val_batch_size,\n",
    "            num_workers=conf.NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "        test_loader = get_protorecdataset_dataloader(\n",
    "            data_path=conf.data_path,\n",
    "            split_set=\"test\",\n",
    "            n_neg=conf.neg_val,\n",
    "            neg_strategy=conf.eval_neg_strategy,\n",
    "            batch_size=conf.val_batch_size,\n",
    "            num_workers=conf.NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"train_loader\": train_loader,\n",
    "            \"val_loader\": val_loader,\n",
    "            \"test_loader\": test_loader,\n",
    "        }\n",
    "    else:\n",
    "        test_loader = get_protorecdataset_dataloader(\n",
    "            data_path=conf.data_path,\n",
    "            split_set=\"test\",\n",
    "            n_neg=conf.neg_val,\n",
    "            neg_strategy=conf.eval_neg_strategy,\n",
    "            batch_size=conf.val_batch_size,\n",
    "            num_workers=conf.NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "        return {\"test_loader\": test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723ce52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c4bfd87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_loaders_dict = load_data(user_proto_chose_original_hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e6f023c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Built ProtoRecDataset module \n",
      "- data_path: ProtoMF\\data\\ml \n",
      "- n_users: 6028 \n",
      "- n_items: 3123 \n",
      "- n_interactions: 545656 \n",
      "- split_set: train \n",
      "- n_neg: 99 \n",
      "- neg_strategy: uniform \n",
      "\n",
      "Loading data\n",
      "Built ProtoRecDataset module \n",
      "- data_path: ProtoMF\\data\\ml \n",
      "- n_users: 6028 \n",
      "- n_items: 3123 \n",
      "- n_interactions: 14196 \n",
      "- split_set: val \n",
      "- n_neg: 99 \n",
      "- neg_strategy: uniform \n",
      "\n",
      "Loading data\n",
      "Built ProtoRecDataset module \n",
      "- data_path: ProtoMF\\data\\ml \n",
      "- n_users: 6028 \n",
      "- n_items: 3123 \n",
      "- n_interactions: 13952 \n",
      "- split_set: test \n",
      "- n_neg: 99 \n",
      "- neg_strategy: uniform \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_protorecdataset_dataloader(\n",
    "    protomf_path / \"data/ml\", \"train\", 99, batch_size=256\n",
    ")\n",
    "val_loader = get_protorecdataset_dataloader(\n",
    "    protomf_path / \"data\\ml\", \"val\", 99, batch_size=256\n",
    ")\n",
    "test_loader = get_protorecdataset_dataloader(\n",
    "    protomf_path / \"data\\ml\", \"test\", 99, batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f902bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from omegaconf import OmegaConf\n",
    "\n",
    "# OmegaConf.create(proto_double_tie_chose_original_hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab7f1df3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'rec_sys_param'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto_double_tie_chose_original_hyper_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\Documents\\github\\hse_courses\\2nd_year\\term1\\recsys\\project\\ProtoMF\\rec_sys_folder\\trainer.py:27\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, train_loader, val_loader, conf)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m train_loader\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loader \u001b[38;5;241m=\u001b[39m val_loader\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_sys_param \u001b[38;5;241m=\u001b[39m \u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec_sys_param\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mft_ext_param \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39mft_ext_param\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_param \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39moptim_param\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'rec_sys_param'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    train_loader, val_loader, proto_double_tie_chose_original_hyper_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc72c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building FeatureExtractor model ---\n",
      "Built Embedding model \n",
      "- n_objects: 6028 \n",
      "- embedding_dim: 75 \n",
      "- max_norm: None\n",
      "- only_positive: False\n",
      "Built PrototypeEmbedding model \n",
      "- n_prototypes: 71 \n",
      "- use_weight_matrix: False \n",
      "- sim_proto_weight: 7.912332955359149 \n",
      "- sim_batch_weight: 5.745415598212118 \n",
      "- reg_proto_type: max \n",
      "- reg_batch_type: max \n",
      "- cosine_type: shifted \n",
      "\n",
      "--- Finished building FeatureExtractor model ---\n",
      "\n",
      "--- Building FeatureExtractor model ---\n",
      "Built Embedding model \n",
      "- n_objects: 3123 \n",
      "- embedding_dim: 71 \n",
      "- max_norm: None\n",
      "- only_positive: False\n",
      "--- Finished building FeatureExtractor model ---\n",
      "\n",
      "Built RecSys module \n",
      "- n_users: 6028 \n",
      "- n_items: 3123 \n",
      "- user_feature_extractor: PrototypeEmbedding \n",
      "- item_feature_extractor: Embedding \n",
      "- loss_func_name: sampled_softmax \n",
      "- use_bias: False \n",
      "\n",
      "Built Optimizer  \n",
      "- name: adagrad \n",
      "- lr: 0.011408907195512278 \n",
      "- wd: 0.004751680623599311 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adagrad (\n",
       "Parameter Group 0\n",
       "    differentiable: False\n",
       "    eps: 1e-10\n",
       "    foreach: None\n",
       "    initial_accumulator_value: 0\n",
       "    lr: 0.011408907195512278\n",
       "    lr_decay: 0\n",
       "    maximize: False\n",
       "    weight_decay: 0.004751680623599311\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer._build_model()\n",
    "trainer._build_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c94980b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation started\n",
      "Init - Avg Val Value 0.276 \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 0 - Epoch Avg Train Loss 3.783 \n",
      "\n",
      "Validation started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\aleke\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\aleke\\AppData\\Local\\Temp\\ipykernel_13468\\3609282671.py\", line 1, in <module>\n",
      "    trainer.run()\n",
      "  File \"C:\\Users\\aleke\\AppData\\Local\\Temp\\ipykernel_13468\\3527903450.py\", line 114, in run\n",
      "    tune.report({**metrics_values, 'epoch_train_loss': epoch_train_loss})\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Avg Val Value 0.671 \n",
      "\n",
      "Epoch 0 - New best model found (val value 0.671) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 1 - Epoch Avg Train Loss 0.819 \n",
      "\n",
      "Validation started\n",
      "Epoch 1 - Avg Val Value 0.833 \n",
      "\n",
      "Epoch 1 - New best model found (val value 0.833) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 2 - Epoch Avg Train Loss 0.239 \n",
      "\n",
      "Validation started\n",
      "Epoch 2 - Avg Val Value 0.919 \n",
      "\n",
      "Epoch 2 - New best model found (val value 0.919) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 3 - Epoch Avg Train Loss -0.025 \n",
      "\n",
      "Validation started\n",
      "Epoch 3 - Avg Val Value 0.971 \n",
      "\n",
      "Epoch 3 - New best model found (val value 0.971) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 4 - Epoch Avg Train Loss -0.180 \n",
      "\n",
      "Validation started\n",
      "Epoch 4 - Avg Val Value 1.024 \n",
      "\n",
      "Epoch 4 - New best model found (val value 1.024) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 5 - Epoch Avg Train Loss -0.285 \n",
      "\n",
      "Validation started\n",
      "Epoch 5 - Avg Val Value 1.046 \n",
      "\n",
      "Epoch 5 - New best model found (val value 1.046) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 6 - Epoch Avg Train Loss -0.363 \n",
      "\n",
      "Validation started\n",
      "Epoch 6 - Avg Val Value 1.074 \n",
      "\n",
      "Epoch 6 - New best model found (val value 1.074) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 7 - Epoch Avg Train Loss -0.426 \n",
      "\n",
      "Validation started\n",
      "Epoch 7 - Avg Val Value 1.089 \n",
      "\n",
      "Epoch 7 - New best model found (val value 1.089) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 8 - Epoch Avg Train Loss -0.478 \n",
      "\n",
      "Validation started\n",
      "Epoch 8 - Avg Val Value 1.104 \n",
      "\n",
      "Epoch 8 - New best model found (val value 1.104) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 9 - Epoch Avg Train Loss -0.524 \n",
      "\n",
      "Validation started\n",
      "Epoch 9 - Avg Val Value 1.122 \n",
      "\n",
      "Epoch 9 - New best model found (val value 1.122) \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n",
      "Epoch 10 - Epoch Avg Train Loss -0.566 \n",
      "\n",
      "Validation started\n",
      "Epoch 10 - Avg Val Value 1.119 \n",
      "\n",
      "0_users_past\n",
      "2000_users_past\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 92\u001b[0m, in \u001b[0;36mTrainer.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     90\u001b[0m epoch_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u_idxs, i_idxs, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[0;32m     93\u001b[0m     u_idxs \u001b[38;5;241m=\u001b[39m u_idxs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     94\u001b[0m     i_idxs \u001b[38;5;241m=\u001b[39m i_idxs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[24], line 160\u001b[0m, in \u001b[0;36mProtoRecDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Select the correct negative sampling strategy\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneg_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 160\u001b[0m     neg_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neg_sample_uniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneg_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopular\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    162\u001b[0m     neg_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neg_sample_popular(user_idx)\n",
      "Cell \u001b[1;32mIn[24], line 117\u001b[0m, in \u001b[0;36mProtoRecDataset._neg_sample_uniform\u001b[1;34m(self, row_idx)\u001b[0m\n\u001b[0;32m    115\u001b[0m p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_items)\n\u001b[0;32m    116\u001b[0m p[consumed_items] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m  \u001b[38;5;66;03m# Excluding consumed items\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m sampled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_items), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_neg, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, p\u001b[38;5;241m=\u001b[39mp)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "608d4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_up = torch.load(checkpoint_dir + \"/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1debe6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_feats = np.array(\n",
    "    model_up[\"item_feature_extractor.embedding_layer.weight\"].to(\"cpu\")\n",
    ")\n",
    "user_protos = np.array(model_up[\"user_feature_extractor.prototypes\"].to(\"cpu\"))\n",
    "user_embeds = np.array(\n",
    "    model_up[\"user_feature_extractor.embedding_ext.embedding_layer.weight\"].to(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "705913a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_mat_users = np.array(\n",
    "    ((user_embeds.T) * 1 / np.linalg.norm(user_embeds, 2, axis=1))\n",
    ")\n",
    "normed_mat_protos = np.array(\n",
    "    ((user_protos.T) * (1 / np.linalg.norm(user_protos, 2, axis=1)))\n",
    ")\n",
    "user_to_protos = 1 + np.dot(normed_mat_users.T, normed_mat_protos)\n",
    "scores = user_to_protos.dot(items_feats.T)\n",
    "top_20 = scores.argsort()[:, ::-1][:, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cb3bc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 526,  222,  926, ...,   98,   48,  927],\n",
       "       [ 222,  926, 2257, ..., 2137, 2179,  930],\n",
       "       [ 926,  222, 2257, ...,   98,  944, 1254],\n",
       "       ...,\n",
       "       [ 926, 2257,  928, ..., 2137,  940, 2375],\n",
       "       [2257,  526,  222, ...,  511,    0,  944],\n",
       "       [ 526,  928,  222, ..., 2137,  864,  944]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cd29443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid = pd.read_excel(\n",
    "    r\"C:\\Users\\aleke\\Downloads\\KION_DATASET\\ProtoMF\\data\\ml\\valid_ml_our_split.xlsx\"\n",
    ")\n",
    "test = pd.read_excel(\n",
    "    r\"C:\\Users\\aleke\\Downloads\\KION_DATASET\\ProtoMF\\data\\ml\\test_ml_our_split.xlsx\"\n",
    ")\n",
    "train = pd.read_excel(\n",
    "    r\"C:\\Users\\aleke\\Downloads\\KION_DATASET\\ProtoMF\\data\\ml\\train_ml_our_split.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53f9cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_score(top_n_items, real_likes):\n",
    "    mask = (top_n_items[..., None] == real_likes[:, None]).any(2)\n",
    "    return mask.any(axis=1).mean()\n",
    "\n",
    "\n",
    "def mrr_score(top_n_items, real_likes):\n",
    "    idx = np.arange(1, top_n_items.shape[1] + 1)[None, :]\n",
    "    mask = (top_n_items[..., None] == real_likes[:, None]).any(2)\n",
    "    return (mask / idx).max(axis=1).mean()\n",
    "\n",
    "\n",
    "def coverage_score(top_n_items, total_item_count):\n",
    "    return len(np.unique(top_n_items)) * 1.0 / total_item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e9ff40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_likes = test.groupby(\"userid\")[\"itemid\"].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf4b7c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4154676258992806"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_likes = test.groupby(\"userid\")[\"itemid\"].apply(\n",
    "    lambda x: list(np.pad(x, (0, max_likes - len(x)), \"constant\", constant_values=-1))\n",
    ")\n",
    "\n",
    "test_users = test_likes.index\n",
    "test_likes = np.asarray(list(test_likes))\n",
    "hr_score(top_20[test_users], np.array(test_likes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
